{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikhilSengar/Capstone-2---Yes-Bank-Stock-Closing-Price-Prediction/blob/main/Yes_Bank_Stock_Closing_Price_Prediction_Nikhil_Sengar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Yes Bank Stock Closing Price Prediction**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name** - Nikhil Sengar\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main objective of this project is to analyze the impact of fraud case involving Rana Kapoor on the stock price of Yes Bank, Yes Bank is well known bank in Indian financial domain. The dataset which is used in this project consist of five columns Date, Open, High, Low, Close.\n",
        "\n",
        "I have done this project in seven parts which are dataset information , understanding the variables, Data wrangling , data visualization, hypothesis testing, featured engineering and data pre-processing, final stepies machine learning model implementation.\n",
        "\n",
        "In first part of my project I have done exploratory data analysis to familiarize with the dataset order to perform pre-processing and data cleaning. Hindi processing and cleaning. I have found out about  duplicate value and missing value / null value.\n",
        "The second part is to understand the variable, in this, I need to understand variable description from my data set and check the unique value /null value/ missing value for each variable.\n",
        "\n",
        "In third part, I have done data wrangling in which I have converted date column into date time, found out the information about my data set by using info function. After that I divided my data set into two variables. One is independent variables which has high, low, open variables and dependent variables which is close price. After that I have done a data visualization, hypothesis, testing, feature, engineering and data preprocessing.\n",
        "\n",
        "Multiple machine learning models were evaluated, including Linear Regression, Lasso, Ridge, K-Nearest Neighbors, and Random Forest. The models were assessed using key evaluation metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R2 score, and Adjusted R2 score.The results indicated that all models performed well, with high R2 and adjusted R2 scores, suggesting strong predictive capabilities.\n",
        "\n",
        "The Linear Regression model emerged as the top performer, exhibiting the lowest MAE, MSE, and RMSE among the candidates, making it the preferred choice for the final model.\n",
        "\n",
        "In conclusion, the Yes Bank Stock Closing Price Prediction project successfully developed a predictive model. The project underscores the significance of data-driven approaches in the finance industry and the potential benefits of combining machine learning with domain expertise for more accurate predictions and insights."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/NikhilSengar/Capstone-2---Yes-Bank-Stock-Closing-Price-Prediction/blob/main/Yes_Bank_Stock_Closing_Price_Prediction_Nikhil_Sengar.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes Bank is a well-known bank in the Indian financial domain. Since 2018, it has been in the news because of the fraud case involving Rana Kapoor. Owing to this fact, it was interesting to see how that impacted the stock prices of the company and whether Time series models or any other predictive models can do justice to such situations. This dataset has monthly stock prices of the bank since its inception and includes closing, starting, highest, and lowest stock prices of every month. The main objective is to predict the stockâ€™s closing price of the month."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Scaling the Data\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split Train and Test Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import (Lasso, Ridge,ElasticNet)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WPwmM7NrV1Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/ML Project/Regression/data_YesBank_StockPrices.csv')\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.tail()"
      ],
      "metadata": {
        "id": "6d9UaDM2WkCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(dataset.isnull())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our dataset, there are 185 rows and 5 columns. In this data we have monthly stock price from July 2005 to November 2020. There are total five columns.  Date, Open, High, Low are the independent variables and Close is dependent variable. There are no Missing values and Duplicate values in the dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date** - Date of the record.  It has month and year for a particular price.\n",
        "\n",
        "**Open** - Opening price of the stock for that Month.\n",
        "\n",
        "**High** - Highest price of the Month.\n",
        "\n",
        "**Low** -  Lowest price of the Month.\n",
        "\n",
        "**Close** -  Closing price of the stock for that Month"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "dataset_1= dataset.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting 'Date' into datetime\n",
        "from datetime import datetime\n",
        "\n",
        "dataset_1['Date']=pd.to_datetime(dataset_1['Date'].apply(lambda x: datetime.strptime(x,'%b-%y')))"
      ],
      "metadata": {
        "id": "oV-oy30utinH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1.head()"
      ],
      "metadata": {
        "id": "77RF0ZT0trpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1.info()            # As we can see Dtype of date is converted from object to datetime64."
      ],
      "metadata": {
        "id": "A2u2THU3t4DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting the Date as index.\n",
        "dataset_1.set_index('Date', inplace=True)"
      ],
      "metadata": {
        "id": "T86vIFHQwONz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_1.head()\n"
      ],
      "metadata": {
        "id": "P5ES6Q7iwTTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seperating the data\n",
        "indep_var = dataset_1[['High','Low','Open']]\n",
        "dep_var = dataset_1['Close']"
      ],
      "metadata": {
        "id": "KSQGeGzIumGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(indep_var.shape)\n",
        "print(dep_var.shape)"
      ],
      "metadata": {
        "id": "5FtVVrNfxWQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I change the datatype of date variable to datetime , then set the date as index. Rather than date remaining, all the variables are numerical variables. I separate my dataset in two variables, one is dependent and other is independent visible. Open, High, Low are independent variables and Close ease dependent variable."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Yearly Closing Price\n",
        "\n",
        "plt.figure(figsize=(15,5))\n",
        "dataset_1['Close'].plot(color = 'r')\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Closing Price')\n",
        "plt.title('Yearly Closing Price')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the variation in price every year."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here in chart, the share price drop drastically in year 2018. The reason that is the fraud case of 2018 involving Rana Kapoor.  "
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, Due to Fraud happen in 2018 in Yes bank stock suffered immensily. So that this could not happen again in future Risk Assessment must be done."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution of Dependent variable 'Close'\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.distplot(dataset['Close'],color=\"y\")"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Distribution plots are useful for visualizing the distribution of a univariate (single-variable) dataset, We are using it here for checking the distribution of dependent variable(Close)."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the chart the data is right skewed."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the chart shows the distribution is highly skewed toward right so we need to improve it by applying log transformation."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependent variable 'Close'\n",
        "# By Applying log transformation to improve skewness\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.distplot(np.log10(dataset['Close']),color=\"y\")"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the distribution of dependent variable."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying log transformation skewness is improved and now the pattern is look like a normal distribution."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the data is normally distributed, it Enhanced the Performance of Model."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distributions of Independent Variables.\n",
        "\n",
        "for col in indep_var:\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "  ax = fig.gca()\n",
        "  feature = dataset_1[col]\n",
        "  sns.distplot(dataset_1[col], color='b')\n",
        "  plt.xlabel(col, fontsize=10)\n",
        "\n",
        "  # Plotting mean and median\n",
        "  ax.axvline(feature.mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(feature.median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using it here for checking the distribution of independent variable."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in the chart the data of all independent variables are right skewed."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the chart shows the distribution of all independent variables are  highly skewed toward right so we need to improve it by applying log transformation."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distributions of Independent Variables.\n",
        "# By Applying log transformation to improve skewness\n",
        "\n",
        "for col in indep_var:\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "  ax = fig.gca()\n",
        "  feature = dataset_1[col]\n",
        "  sns.distplot(np.log10(dataset_1[col]), color='b')\n",
        "  plt.xlabel(col, fontsize=12)\n",
        "\n",
        "  # Plotting mean and median\n",
        "  ax.axvline(np.log10(feature).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "  ax.axvline(np.log10(feature).median(), color='cyan', linestyle='dashed', linewidth=2)\n",
        "  ax.set_title(col)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check the distribution of independent variable after the log transformation has done."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying log transformation skewness is improved and now the pattern is look like a normal distribution."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When the data is normally distributed, it Enhanced the Performance of Model."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking Correlation between Independent and Dependent Varieble.\n",
        "\n",
        "for col in indep_var:\n",
        "  fig = plt.figure(figsize=(6, 4))\n",
        "  ax = fig.gca()\n",
        "  feature = dataset_1[col]\n",
        "  label = dataset_1['Close']\n",
        "\n",
        "  # calculating the correlation\n",
        "  correlation = feature.corr(label)\n",
        "  plt.scatter(x=feature, y=label)\n",
        "  plt.xlabel(col)\n",
        "  plt.ylabel('Close')\n",
        "  ax.set_title('Close vs ' + col + '- correlation: ' + str(correlation))\n",
        "  z = np.polyfit(dataset[col], dataset['Close'], 1)\n",
        "  y_hat = np.poly1d(z)(dataset[col])\n",
        "\n",
        "  plt.plot(dataset[col], y_hat, \"r--\", lw=1)"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To plot the correlation between Independent and Dependent Variable."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above chart we can see that the Dependent and Independent Variable are Correlated to each other."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " There is good correlation showing in the above chart it refers to a strong and meaningful linear relationship between dependent variable and a independent variable."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "correlation = dataset_1.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This map is use to Identifying Correlations between the Variables."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see in above chart the variables are not vary in large scale so that we can say that all the independent variables are correlated to each other."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It shows strong linear relationship, This means that as the Independent variable increases, the dependent variable tends to increase as well. In other words, they move in the same direction."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1 - Performing hypothesis testing on the coefficients of a regression model for predicting Yes Bank stock closing prices based on different time periods (e.g., the first half and the second half of the dataset) involves splitting the dataset and conducting separate hypothesis tests for each time period.\n",
        "\n",
        "Statement 2 - Hypothesis testing is performing on the coefficients of the model, specifically focusing on the 'High' variable.\n",
        "\n",
        "Statement 3 - A hypothesis test to determine whether there is a statistically significant correlation between the opening and closing prices of the dataset."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The null hypothesis states that a particular predictor variable has no effect on predicting the Yes Bank stock closing price in the specified time period.\n",
        "\n",
        "Alternative Hypothesis (H1): The alternative hypothesis states that a particular predictor variable does have an effect on predicting the Yes Bank stock closing price in the specified time period."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "dataset_2= dataset.copy()\n",
        "\n",
        "# Define the date range for splitting the dataset\n",
        "start_date_period1 = '2005-01-01'\n",
        "end_date_period1 = '2017-12-31'\n",
        "start_date_period2 = '2018-01-01'\n",
        "end_date_period2 = '2020-12-31'\n",
        "\n",
        "# Create masks for selecting data within the specified time periods\n",
        "period_1 = (dataset_2['Date'] >= start_date_period1) & (dataset_2['Date'] <= end_date_period1)\n",
        "period_2 = (dataset_2['Date'] >= start_date_period2) & (dataset_2['Date'] <= end_date_period2)\n",
        "\n",
        "# means and standard deviations for both time periods.\n",
        "mean1 = np.mean(period_1)\n",
        "mean2 = np.mean(period_2)\n",
        "std1 = np.std(period_1)\n",
        "std2 = np.std(period_2)\n",
        "\n",
        "# Calculate the sample sizes(number of observations)\n",
        "n1 = len(period_1)\n",
        "n2 = len(period_2)\n",
        "\n",
        "# Calculate the standard error of the difference between means\n",
        "standard_error = np.sqrt((std1**2 / n1) + (std2**2 / n2))\n",
        "\n",
        "# Calculate the z-score\n",
        "z = (mean1 - mean2) / standard_error\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - stats.norm.cdf(abs(z)))   # two-tailed test\n",
        "\n",
        "# Set significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Compare the p-value with the significance level\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis. There is a significant difference in means.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. There is no significant difference in means.\")\n"
      ],
      "metadata": {
        "id": "ChjnMOvEWp3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Z test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Z-test is commonly used when you have a large sample size and want to compare a difference between means."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): The coefficient of 'High' is equal to zero (no effect).\n",
        "\n",
        "Alternative Hypothesis (H1): The coefficient of 'High' is not equal to zero (there is an effect).\n",
        "\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# predictor variables (features) in X and the target variable in y\n",
        "X = dataset_1[['High','Low','Open']]\n",
        "y = dataset_1['Close']\n",
        "\n",
        "# Fit a linear regression model\n",
        "X = sm.add_constant(X)  # Add a constant term (intercept)\n",
        "model = sm.OLS(y, X).fit()  # sm.OLS(y, X).fit(), the library performs ordinary least squares (OLS) regression\n",
        "\n",
        "# Perform hypothesis testing on the coefficients using statsmodels\n",
        "summary = model.summary()\n",
        "\n",
        "# Print a summary of the regression model, including coefficients and p-values\n",
        "print(summary)\n",
        "\n",
        "# Hypothesis testing for a specific coefficient\n",
        "feature_name = 'High'\n",
        "p_value = model.pvalues[feature_name]\n",
        "\n",
        "# Compare the p-value to alpha to determine statistical significance\n",
        "if p_value < alpha:\n",
        "    print(f\"Reject the null hypothesis (H0) for {feature_name}: The coefficient is statistically significant.\")\n",
        "    print(f\"Accept the alternative hypothesis (H1) for {feature_name}: The coefficient is not equal to zero.\")\n",
        "else:\n",
        "    print(f\"Fail to reject the null hypothesis (H0) for {feature_name}: The coefficient is not statistically significant.\")\n",
        "    print(f\"Fail to accept the alternative hypothesis (H1) for {feature_name}: The coefficient is equal to zero.\")\n",
        "\n",
        "# Set significance level (alpha)\n",
        "alpha = 0.05"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used the statsmodels library in Python, which internally performs t-tests to obtain p-values for each coefficient in the regression model."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statsmodels provides a detailed summary output of regression results, including coefficients, standard errors, t-statistics, p-values, confidence intervals, and goodness-of-fit statistics. This summary is useful for understanding the statistical significance and overall performance of the regression model."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no significant correlation between opening and closing prices.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant correlation between opening and closing prices.\n"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# Assuming you have the opening prices ('Open') and closing prices ('Close') as predictor variables\n",
        "X = dataset_1[['Open']]\n",
        "y = dataset_1['Close']\n",
        "\n",
        "# Perform a correlation test (e.g., Pearson correlation) between opening and closing prices\n",
        "correlation_coefficient, p_value = stats.pearsonr(X['Open'], y)\n",
        "\n",
        "# Set the significance level (alpha) for the test\n",
        "alpha = 0.05\n",
        "\n",
        "# Determine whether to reject or fail to reject the null hypothesis based on the p-value\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis (H0): There is a significant correlation between opening and closing prices.\")\n",
        "    print(\"Accept the alternative hypothesis (H1): There is a significant correlation between opening and closing prices.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (H0): There is no significant correlation between opening and closing prices.\")\n",
        "    print(\"Fail to accept the alternative hypothesis (H1): There is no significant correlation between opening and closing prices.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used the Pearson correlation coefficient test to obtain the p-value."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Pearson correlation coefficient, measures the strength and direction of a linear relationship between two continuous variables. In this case, we applied the Pearson correlation test to assess the correlation between the opening prices ('Open') and closing prices ('Close') of Yes Bank stock.\n",
        "\n",
        " The p-value obtained from the Pearson correlation test allows us to assess whether the observed correlation between the two variables is statistically significant."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "#There are no missing values in the dataset\n",
        "\n",
        "dataset_1.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "#Transformation has taken care of outliers, so no need to treat outliers."
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "#There are no categorical variables in this dataset."
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "#dataset_1['Mean_independent_var'] = dataset_1[['Open', 'High', 'Low']].mean(axis=1)\n",
        "#dataset_1.head()\n",
        "\n",
        "# I do not need to create a new features."
      ],
      "metadata": {
        "id": "F3ppZLOOLwsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Independent Variables.\n",
        "indep_var"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dependent variable\n",
        "dep_var"
      ],
      "metadata": {
        "id": "2EFzSHiGZWoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Open, High, Low, Close all are the important feature because they provide valuable information about the trading activity and price movement of a stock during a specific time period"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "# Need to done after train_test_split\n",
        "#scaler = MinMaxScaler()\n",
        "#x_train = scaler.fit_transform(x_train)\n",
        "#x_test = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am using MinMaxScaler."
      ],
      "metadata": {
        "id": "LCNSNunJR1fU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, Because I have only few features in my dataset, Due to that dimensionality reduction is not necessary."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(indep_var, dep_var, test_size = 0.2, random_state=1)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X_train = \", X_train.shape)\n",
        "print(\"Shape of y_train = \", y_train.shape)\n",
        "print(\"Shape of X_test = \", X_test.shape)\n",
        "print(\"Shape of y_test = \", y_test.shape)"
      ],
      "metadata": {
        "id": "RwwKmCxThBhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "EmVBjr8858kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used 80 % of the data for training the model and 20 % data for testing the model."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No, dataset is not imbalanced."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> ML Model - 1 - Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of Linear Regression\n",
        "\n",
        "# Fit the Algorithm\n",
        "reg = LinearRegression()\n",
        "reg = LinearRegression().fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred = reg.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "rmdSQjlITdM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.values"
      ],
      "metadata": {
        "id": "3vIsqHGIVpsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "print('MAE',MAE)\n",
        "\n",
        "MSE = mean_squared_error(y_test,y_pred)\n",
        "print('MSE',MSE)\n",
        "\n",
        "RMSE = np.sqrt(mean_squared_error(y_test,y_pred))\n",
        "print('RMSE',RMSE)\n",
        "\n",
        "r2 = r2_score(y_test,y_pred)\n",
        "print('R2_score',r2)\n",
        "\n",
        "adjusted_r2 = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2', adjusted_r2)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics = ['MAE', 'MSE', 'RMSE', 'R2_score', 'Adjusted R2']\n",
        "scores = [MAE, MSE, RMSE, r2, adjusted_r2]\n",
        "\n",
        "# Plot the evaluation metric score chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics, scores)\n",
        "plt.xlabel('Evaluation Metric')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric Score Chart for Linear Regression with Transformation')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7RNwA6pcpXn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for comparing actual and predicted Values.\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_pred)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RPXcp5BEk2Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_regessor_list = {'Mean Absolute Error':MAE, 'Mean squared Error' : MSE,\n",
        "                        'Root Mean squared Error' : RMSE, 'R2 score' : r2, 'Adjusted R2 score' : adjusted_r2}\n",
        "\n",
        "metrics = pd.DataFrame.from_dict(linear_regessor_list, orient='index').reset_index()\n",
        "metrics = metrics.rename(columns={'index':'Metric',0:'Lr_Metric_Score'})\n",
        "metrics"
      ],
      "metadata": {
        "id": "Pgybru91q_gr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C0sY03pl4BP"
      },
      "source": [
        "#### Implementing Lasso regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lasso  = Lasso(alpha=0.1 , max_iter= 3000)\n",
        "\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Zy_LkTfd7HiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lasso.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "hJLY7yd77qrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_l = lasso.predict(X_test)"
      ],
      "metadata": {
        "id": "iSqoflya74lB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "wujFEzeiolu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15,1e-13,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1e-1,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "lasso_regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "3-stRkAi8efs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,lasso_regressor.best_params_)\n",
        "print(\"\\nUsing \",lasso_regressor.best_params_, \" the negative mean squared error is: \", lasso_regressor.best_score_)"
      ],
      "metadata": {
        "id": "QQiXSDDj86ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred_lasso = lasso_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "vKvMWLBB9Tvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_l_CV = mean_absolute_error(y_test, y_pred_lasso)\n",
        "print('MAE',MAE_l_CV)\n",
        "\n",
        "MSE_l_CV = mean_squared_error(y_test,y_pred_lasso)\n",
        "print('MSE',MSE_l_CV)\n",
        "\n",
        "RMSE_l_CV = np.sqrt(mean_squared_error(y_test,y_pred_lasso))\n",
        "print('RMSE',RMSE_l_CV)\n",
        "\n",
        "r2_l_CV = r2_score(y_test,y_pred_lasso)\n",
        "print('R2_score',r2_l_CV)\n",
        "\n",
        "adjusted_r2_l_CV = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2', adjusted_r2_l_CV)"
      ],
      "metadata": {
        "id": "a5zW7lBi9zII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['lasso_CV'] = [MAE_l_CV, MSE_l_CV, RMSE_l_CV, r2_l_CV, adjusted_r2_l_CV]\n"
      ],
      "metadata": {
        "id": "uv4OB2uAIsES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for comparing actual and predicted Values.\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_pred_lasso)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pQlYHiMv-T_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoRYiZhy-fhT"
      },
      "source": [
        "#### Implementing Ridge regression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge  = Ridge(alpha=0.1)"
      ],
      "metadata": {
        "id": "KUoMi5Oc-l-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "GjwrvUDH-xs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridge.score(X_train, y_train)"
      ],
      "metadata": {
        "id": "ta-eu_UU-3QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_r = ridge.predict(X_test)"
      ],
      "metadata": {
        "id": "o-P4dOza-7we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.1 Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "pv1EO_T6oxE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross validation\n",
        "\n",
        "ridge = Ridge()\n",
        "parameters = {'alpha': [1e-15,1e-10,1e-8,1e-5,1e-4,1e-3,1e-2,1,5,10,20,30,40,45,50,55,60,100]}\n",
        "ridge_regressor = GridSearchCV(ridge, parameters, scoring='neg_mean_squared_error', cv=3)\n",
        "ridge_regressor.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "8NAFRky9_E4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The best fit alpha value is found out to be :\" ,ridge_regressor.best_params_)\n",
        "print(\"\\nUsing \",ridge_regressor.best_params_, \" the negative mean squared error is: \", ridge_regressor.best_score_)"
      ],
      "metadata": {
        "id": "XrPcoktk_io7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Prediction\n",
        "\n",
        "y_pred_ridge = ridge_regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "yJo-1Hcg_q74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_CV = mean_absolute_error(y_test, y_pred_ridge)\n",
        "print('MAE',MAE)\n",
        "\n",
        "MSE_CV = mean_squared_error(y_test,y_pred_ridge)\n",
        "print('MSE',MSE)\n",
        "\n",
        "RMSE_CV = np.sqrt(mean_squared_error(y_test,y_pred_ridge))\n",
        "print('RMSE',RMSE)\n",
        "\n",
        "r2_CV = r2_score(y_test,y_pred_ridge)\n",
        "print('R2_score',r2)\n",
        "\n",
        "adjusted_r2_CV = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2', adjusted_r2_CV)"
      ],
      "metadata": {
        "id": "Ay_fTuzd_0T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['ridge_CV'] = [MAE_CV, MSE_CV, RMSE_CV, r2_CV, adjusted_r2_CV]\n"
      ],
      "metadata": {
        "id": "Qfs6Sr8WupOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_ridge_model1 = ridge_regressor.best_estimator_\n",
        "\n",
        "print(best_ridge_model1.coef_)\n",
        "print(best_ridge_model1.intercept_)"
      ],
      "metadata": {
        "id": "6KTAWZyPLuAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for comparing actual and predicted Values.\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_pred_ridge)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qDrJ1dtLNu2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV hyperparameter optimization technique which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = metrics[['Metric','Lr_Metric_Score', 'ridge_CV']]\n",
        "print(model_1)\n",
        "\n",
        "# metrics - for comparision of all models."
      ],
      "metadata": {
        "id": "G46tpCqZvpol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every value is similar after doing cross validation and it is possible that the model is overfitting."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "fBepaqS552GP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAE** (Mean Absolute Error):: Both models have low MAE, indicating accurate predictions that can improve business decision-making and resource allocation.\n",
        "\n",
        "**MSE** (Mean Squared Error): Both models have low MSE, reducing errors in decision-making, especially for significant impacts on the business.\n",
        "\n",
        "**RMSE** (Root Mean Squared Error): Similar RMSE values indicate a clear understanding of typical prediction error magnitudes, aiding informed business decisions.\n",
        "\n",
        "**R2 Score **(R-squared): High R2 scores for both models suggest effective capturing of data patterns, enabling accurate forecasting and informed decisions.\n",
        "\n",
        "Adjusted R2 Score (Adjusted R-squared): Identical scores imply similar performance in explaining variance while maintaining model simplicity, which can lead to cost-effective modeling.\n",
        "\n",
        "In summary, both models offer accurate predictions, reduced errors, and better decision support, positively impacting the business."
      ],
      "metadata": {
        "id": "-5DwnoAR52Gb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> ML Model - 2 - KNN"
      ],
      "metadata": {
        "id": "uUB2PNnmf8AN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of KNN\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn = KNeighborsRegressor(n_neighbors = 5)\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "eSbuMinAhT8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "1DPYTSpmiMNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "y_pred_knn"
      ],
      "metadata": {
        "id": "PhdPQ2n-kV_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.values"
      ],
      "metadata": {
        "id": "LYZkOo8RlAeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_knn = mean_absolute_error(y_test, y_pred_knn)\n",
        "print('MAE_knn',MAE_knn)\n",
        "\n",
        "MSE_knn = mean_squared_error(y_test,y_pred_knn)\n",
        "print('MSE_knn',MSE_knn)\n",
        "\n",
        "RMSE_knn = np.sqrt(mean_squared_error(y_test,y_pred_knn))\n",
        "print('RMSE_knn',RMSE_knn)\n",
        "\n",
        "r2_knn = r2_score(y_test,y_pred_knn)\n",
        "print('R2_score_knn',r2_knn)\n",
        "\n",
        "adjusted_r2_knn = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2_knn', adjusted_r2_knn)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['KNN_Metric_Score'] = [MAE_knn, MSE_knn, RMSE_knn, r2_knn, adjusted_r2_knn]"
      ],
      "metadata": {
        "id": "eUDtdxDetY2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics_knn = ['MAE_knn', 'MSE_knn', 'RMSE_knn', 'R2_score_knn', 'Adjusted R2_knn']\n",
        "scores_knn = [MAE_knn, MSE_knn, RMSE_knn, r2_knn, adjusted_r2_knn]\n",
        "\n",
        "# Plot the evaluation metric score chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics_knn, scores_knn)\n",
        "plt.xlabel('Evaluation Metric')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric Score Chart for KNN')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "C-a5VMcBmXeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for comparing actual and predicted Values.\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_pred_knn)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yWCpnTyxm9c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "knn = KNeighborsRegressor()\n",
        "param_grid = {'n_neighbors':np.arange(1,10)}\n",
        "knn_cv = GridSearchCV(knn, param_grid, cv=5)\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn_cv.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_knn_cv = knn_cv.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_knn_cv = mean_absolute_error(y_test, y_pred_knn_cv)\n",
        "print('MAE_knn_cv',MAE_knn_cv)\n",
        "\n",
        "MSE_knn_cv = mean_squared_error(y_test,y_pred_knn_cv)\n",
        "print('MSE_knn_cv',MSE_knn_cv)\n",
        "\n",
        "RMSE_knn_cv = np.sqrt(mean_squared_error(y_test,y_pred_knn_cv))\n",
        "print('RMSE_knn_cv',RMSE_knn_cv)\n",
        "\n",
        "r2_knn_cv = r2_score(y_test,y_pred_knn_cv)\n",
        "print('r2_knn_cv',r2_knn_cv)\n",
        "\n",
        "adjusted_r2_knn_cv = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('adjusted_r2_knn_cv', adjusted_r2_knn_cv)"
      ],
      "metadata": {
        "id": "BxxUbbNvn-Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['KNN_CV'] = [MAE_knn_cv, MSE_knn_cv, RMSE_knn_cv, r2_knn_cv, adjusted_r2_knn_cv]"
      ],
      "metadata": {
        "id": "Xlzbhw9quNaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV hyperparameter optimization technique.It's a good choice when you have a limited number of hyperparameters."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = metrics[['Metric','KNN_Metric_Score', 'KNN_CV']]\n",
        "print(model_2)\n",
        "\n",
        "# metrics - for comparision of all models."
      ],
      "metadata": {
        "id": "QmOQFm4ew6Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values represent how much each metric has changed with the updates. Increased values indicate an improvement, while Decreased values indicate a degradation in performance."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each evaluation metric in machine learning provides specific insights into the performance of a model.\n",
        "\n",
        "**MAE** (Mean Absolute Error): Lower MAE indicates more accurate predictions, which can reduce errors in decision-making and potentially lower costs or improve resource allocation.\n",
        "\n",
        "**MSE** (Mean Squared Error): Lower MSE is desirable for reducing errors in decision-making, especially if larger errors are costly.\n",
        "\n",
        "**RMSE** (Root Mean Squared Error): RMSE provides a clear understanding of typical error magnitude in the same units as the target variable, aiding in decision-making.\n",
        "\n",
        "**R2 Score** (R-squared): Higher R2 indicates the model's ability to explain data variance, helping to understand how well the model captures patterns in the data.\n",
        "\n",
        "Adjusted R2 Score (Adjusted R-squared): Adjusted R2 assesses the value of adding more features, aiding cost-effective modeling by penalizing irrelevant variables."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <b> ML Model - 3 - Random Forest Regression"
      ],
      "metadata": {
        "id": "rx94uUtg3pid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementation of KNN Random Forest Regression\n",
        "rf = RandomForestRegressor()\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf.fit(X_train,y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "y_pred_rf"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.values"
      ],
      "metadata": {
        "id": "TNXUE5v_8cia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.score(X_test, y_test)"
      ],
      "metadata": {
        "id": "t9CjxrwN8HzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "print('MAE_rf',MAE_rf)\n",
        "\n",
        "MSE_rf = mean_squared_error(y_test,y_pred_rf)\n",
        "print('MSE_rf',MSE_rf)\n",
        "\n",
        "RMSE_rf = np.sqrt(mean_squared_error(y_test,y_pred_rf))\n",
        "print('RMSE_rf',RMSE_rf)\n",
        "\n",
        "r2_rf = r2_score(y_test,y_pred_rf)\n",
        "print('R2_score_rf',r2_rf)\n",
        "\n",
        "adjusted_r2_rf = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2_rf', adjusted_r2_rf)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['RF_Metric_Score'] = [MAE_rf, MSE_rf, RMSE_rf, r2_rf, adjusted_r2_rf]"
      ],
      "metadata": {
        "id": "_9Z4Krjw9HJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "metrics_rf = ['MAE_rf', 'MSE_rf', 'RMSE_rf', 'R2_score_rf', 'Adjusted R2_rf']\n",
        "scores_rf = [MAE_rf, MSE_rf, RMSE_rf, r2_rf, adjusted_r2_rf]\n",
        "\n",
        "# Plot the evaluation metric score chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(metrics_rf, scores_rf)\n",
        "plt.xlabel('Evaluation Metric')\n",
        "plt.ylabel('Score')\n",
        "plt.title('Evaluation Metric Score Chart for Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RND9-pq19X6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot for comparing actual and predicted Values.\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_pred_rf)\n",
        "plt.plot(np.array(y_test))\n",
        "plt.legend([\"Predicted\",\"Actual\"])\n",
        "plt.xlabel('No of Test Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E7QVmGrk92GJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques\n",
        "\n",
        "grid_values = {'n_estimators':[50, 80,  100], 'max_depth':[3, 5, 7]}\n",
        "\n",
        "rf_cv = GridSearchCV(rf, grid_values, cv=5, scoring='r2')\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "rf_cv.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf_cv = rf_cv.predict(X_test)\n"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "MAE_rf_cv = mean_absolute_error(y_test, y_pred_rf_cv)\n",
        "print('MAE_rf_cv',MAE_rf_cv)\n",
        "\n",
        "MSE_rf_cv = mean_squared_error(y_test,y_pred_rf_cv)\n",
        "print('MSE_rf_cv',MSE_rf_cv)\n",
        "\n",
        "RMSE_rf_cv = np.sqrt(mean_squared_error(y_test,y_pred_rf_cv))\n",
        "print('RMSE_rf_cv',RMSE_rf_cv)\n",
        "\n",
        "r2_rf_cv = r2_score(y_test,y_pred_rf_cv)\n",
        "print('R2_score_rf_cv',r2_rf_cv)\n",
        "\n",
        "adjusted_r2_rf_cv = 1 - ((1-r2)*(40-1)/(40-1-1))\n",
        "print('Adjusted R2_rf', adjusted_r2_rf_cv)"
      ],
      "metadata": {
        "id": "VcqrfcRGEFg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['RF_CV'] = [MAE_rf_cv, MSE_rf_cv, RMSE_rf_cv, r2_rf_cv, adjusted_r2_rf_cv]"
      ],
      "metadata": {
        "id": "yP1j_N5zEvBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV is used in Random Forest and other models because it Automates and saves time in hyperparameter tuning. GridSearchCV incorporates cross-validation for robust evaluation."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = metrics[['Metric','RF_Metric_Score', 'RF_CV']]\n",
        "print(model_2)\n",
        "\n",
        "# metrics - for comparision of all models."
      ],
      "metadata": {
        "id": "vZPOKZ3jE_z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The updated Random Forest model shows modest improvements in MAE, MSE, RMSE, and R2 score compared to the original model. These improvements indicate that the updated model's predictions are slightly more accurate and closer to the actual values, which can have a positive impact on the model's performance in practical applications."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **METRICS COMPARISION**"
      ],
      "metadata": {
        "id": "7_e27qoXG_0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "UyfGuO6aHHaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I consider MAE, MSE, RMSE, R2 score, Adjusted R2 score as an Evaluation metrics.\n",
        "\n",
        "**Mean Absolute Error** (MAE): Measures the average magnitude of prediction errors. Useful for assessing how close the model's predictions are to actual stock prices.\n",
        "\n",
        "**Mean Squared Error** (MSE): Measures the average squared prediction errors. Penalizes larger errors, making it important for precise stock price prediction.\n",
        "\n",
        "**Root Mean Squared Error** (RMSE): Measure prediction accuracy and are easy to interpret.Provides a clear understanding of typical prediction error magnitudes\n",
        "\n",
        "**R2 Score** (R-squared): Indicates how well the model explains the variation in stock prices. A higher R2 score implies better understanding of data variability.\n",
        "\n",
        "Adjusted R2 Score : It helps control model complexity. It helps ensure that adding more features to the model adds value rather than complexity,\n",
        "\n",
        "Collectively, these metrics offer a holistic assessment of model performance, helping businesses make informed decisions, reduce costs, and improve forecasting accuracy, ultimately leading to a positive business impact."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will choose Linear Regression (Lr) model as my final prediction model.\n",
        "\n",
        "Because Linear Regression model has the lowest Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE), indicating better prediction accuracy. It has higher R2 score indicates a better fit to the data. All three models (Lr, Lasso, and Ridge) have identical Adjusted R2 scores, It helps control model complexity while maximizing explanatory power.\n",
        "\n",
        "This accuracy can give me a more informed business decisions, improved forecasting, and potentially positive business impact by reducing errors and uncertainties in various applications."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will use SHAP (SHapley Additive exPlanations) as model explainability tool."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install shap"
      ],
      "metadata": {
        "id": "mNfVa7_dbCvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Initialize the SHAP explainer\n",
        "explainer = shap.Explainer(reg, X_train)\n",
        "\n",
        "# Calculate SHAP values for the entire test dataset\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Summary plot to visualize feature importance\n",
        "shap.summary_plot(shap_values, X_test, show=False)\n",
        "plt.title(\"Feature Importance for Linear Regression Model\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5qCiANg3bT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   The target variable is highly dependent on input variables.\n",
        "\n",
        "*   Linear Regression, Ridge Regression, Lasso Regression,  K-Nearest Neighbors and Random Forest models were evaluated.\n",
        "\n",
        "*   The models performed well, achieving high R2 and adjusted R2 scores, indicating strong predictive capability.\n",
        "\n",
        "*   Linear Regression has given the best results with lowest MAE, MSE, RMSE scores.\n",
        "\n",
        "*   Ridge Regression, Lasso Regression,  K-Nearest Neighbors and Random Forest also given almost similar result.\n",
        "\n",
        "*   Feature importance analysis using SHAP highlighted key features influencing predictions.\n",
        "\n",
        "*   The accuracy for each model is more than 90%.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}